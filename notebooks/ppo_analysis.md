# Аналіз результатів навчання PPO агента для Дилеми в'язня

## Огляд отриманих результатів

Аналізуючи графіки та дані, отримані під час навчання PPO агента в середовищі Дилеми в'язня, ми спостерігаємо надзвичайно цікавий результат: **агент навчився стратегії повної кооперації проти всіх типів опонентів**.

## Ключові спостереження

1. **Кооперативна поведінка**:
   - Агент демонструє 100% рівень кооперації проти всіх стратегій, включаючи always_defect
   - Така поведінка різко відрізняється від теоретичних передбачень для класичної Дилеми в'язня

2. **Розподіл винагород**:
   - Найвищі винагороди (~30) проти tit_for_tat, always_cooperate і pavlov
   - Середні винагороди (~15) проти random
   - Найнижчі винагороди проти always_defect

## Висновки

Результати нашого дослідження демонструють, що PPO агент здатен навчитися кооперативної стратегії, яка може бути оптимальною в змішаному середовищі з різними типами опонентів. Це має важливі наслідки для розробки систем ШІ, що взаємодіють з людьми та іншими агентами, демонструючи можливість розвитку 'просоціальної' поведінки без явного програмування.

Для подальших досліджень варто розглянути:

- Вплив різних гіперпараметрів (особливо коефіцієнта ентропії) на формування стратегії
- Багатоагентне навчання, де кілька агентів навчаються одночасно
- Тестування стійкості стратегії в умовах шуму та неповної інформації
